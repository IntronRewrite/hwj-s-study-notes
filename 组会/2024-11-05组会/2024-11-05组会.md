# 2024-11-05组会

[下周计划](#下周计划)

汇报人：何苇洁

日期：2024-11-05



| [**10/22-10/25** ](#10/22-10/25) | [**10/25-10/27**](#10/25-10/27) | [**10/28-10/29**](#**10/28-10/29**) | [**10/30-11/01** ](#**10/30-11/01** ) | [**11/02-11/03**](#11/02-11/03) |
| :------------------------------: | :-----------------------------: | :---------------------------------: | :-----------------------------------: | :-----------------------------: |
|            学习python            |           阅读论文SSD           |               实现SSD               |      使用遗传算法求解多约束问题       |         学习注意力机制          |

## 10/22-10/25 



**学习python**

<img src="https://admin-hwj.oss-cn-beijing.aliyuncs.com/img/202411092014030.png" alt="Python编程基础" style="zoom:50%;" />



## 10/25-10/27 



**阅读论文**
$$
SSD: Single Shot MultiBox Detector
$$
<small>Wei Liu, Dragomir Anguelov, Dumitru Erhan, Christian Szegedy, Scott E. Reed, Cheng-Yang Fu, Alexander C. Berg</small>



**主要贡献**

1. 引入了一种单阶段的多类别多目标检测器，比以前的算法YOLO**更准更快**

2. SSD的核心是使用应用于特征图的小型**卷积滤波器预测**一组固定默认边界框 的类别分数和框偏移量。

3. 为了实现高检测精度,从**不同尺度的特征图**中产生**不同尺度的预测**,并按长宽比明确分离预测

4. 可以在更小的输入图片(300*300)中得到更好的检测效果（相比Faster-rcnn）；

5. 在多个数据集（PASCAL、VOC、COCO、ILSVRC）上面的测试结果表明，它可以获得更高的mAp值；



### 算法流程

1. **采用多尺度特征图用于检测**

   ​	卷积神经网络一般是个金字塔结构，前宽后窄，所以在不同的阶段就可以得到一些比较大的特征图和一些比较小的特征图。一是SSD提取不同尺度的特征图来做检测，大尺度特征图（较靠前的特征图）用来检测小物体，小尺度特征图（较靠后的特征图，感受野大）用来检测大物体；二是SSD采用了不同尺度和长宽比的先验框Anchor box，这个技巧新版本的yolov2也使用了。
   <img src="https://admin-hwj.oss-cn-beijing.aliyuncs.com/img/202411092014031.png" alt="img" style="zoom:50%;" />



2. 采用卷积进行检测

与Yolo最后采用全连接层不同，SSD直接采用卷积对不同的特征图来进行提取检测结果。

3. 设置先验框

![image-20241105080850772](https://admin-hwj.oss-cn-beijing.aliyuncs.com/img/202411092014032.png)

关于预设框，作者的设置图如下：

1、使用不同尺度的6种中间特征图做预测，分别为：conv4_3、conv7、conv8_2、conv9_2、conv10_2、conv11_2、
2、scale设置：最大特征图conv4_3的scale设置为0.1，剩余的特征图的scale从0.2到0.9线性分割，大特征图具有小scale，目的是为了更好的检测小目标
$$
s_k=s_{\min}+\frac{s_{\max}-s_{\min}}{m-1}(k-1),\quad k\in[1,m]
$$
3、aspect ratio设置：所有尺度的特征图都具有1:1 ,1:2, 2:1的尺度，conv7 conv8_2 conv9_2具有额外的1:3 ,3:1 aspect ratio
4、当aspect raito为1时，增加一个scale，值为当前的scale与下一个scale的几何平均值$\sqrt{s_{k}*s_{k+1}}$

![image-20241105042315507](https://admin-hwj.oss-cn-beijing.aliyuncs.com/img/202411092014033.png)

对先验框施加不同的长宽比，并将它们表示为$a_{r}∈{[1,2,3,1,2,1,3]}$。

默认框的宽度（$w_{k}^{a} = s_{k}\sqrt{a_r}$）

高度（$h_{k}^{a} = s_{k}/\sqrt{a_r}$）。

对于宽高比为1，我们还添加了一个默认框，其比例为$s_{k}=\sqrt{s_ks_{k+1}}$，从而每个特征地图位置有6个默认框。

<div style="display: grid; grid-template-columns: 1fr 1fr; gap: 10px;">
    <div>
        <img src="F:\Documents\GitHub\hwj-s-study-notes\组会\2024-11-05组会\assets\anchors4.png" alt="anchors4" style="width: 100%;">
    </div>
    <div>
        <img src="F:\Documents\GitHub\hwj-s-study-notes\组会\2024-11-05组会\assets\anchors3.png" alt="anchors3" style="width: 100%;">
    </div>
    <div>
        <img src="F:\Documents\GitHub\hwj-s-study-notes\组会\2024-11-05组会\assets\anchors1.png" alt="anchors1" style="width: 100%;">
    </div>
    <div>
        <img src="F:\Documents\GitHub\hwj-s-study-notes\组会\2024-11-05组会\assets\anchors2.png" alt="anchors2" style="width: 100%;">
    </div>
</div>

### 网络结构

![img](https://admin-hwj.oss-cn-beijing.aliyuncs.com/img/202411092014034.png)

1. 算法基础网络是 VGG16，将最后两个全连接层改成卷积层，并随后增加了 **4 个卷积层**来构造网络结构。

2. 对其中 6 个不同大小的 feature map 输出生成prior box

3. 分别用两个不同的 **3×3** 的卷积核进行卷积

一个输出分类用的 **confidence**，每个 **default box** 生成 21( VOC 20 classes+1 background）个类别 confidence；

一个输出回归用的 **localization**，每个 **default box** 生成4个坐标值（x, y, w, h）。



conv4_3  fc7  conv6_2  conv7_2  conv8_2  conv9_2

用来检测的**６**个 feature map 的维度(每像素默认框数4,6,6,6,4,4) 

| feature map |  conv4_3  |    fc7     |  conv6_2  | conv7_2 | conv8_2 | conv9_2 |
| :---------: | :-------: | :--------: | :-------: | :-----: | :-----: | :-----: |
|    size     | 512×38×38 | 1024×19×19 | 512×10×10 | 256×5×5 | 256×3×3 | 256×1×1 |

总default bbox数4×38×38+1024×19×19+1024×10×10...=8732 



使用3*3卷积核进行**score**，经过卷积预测器后的输出维度为**(c\*k)×m×n**，这里**c**是类别总数，**k**是该层设定的default box种类（不同层k的取值不同，分别为4,6,6,6,4,4），维度变化为

| layer | conv4_3_norm_mbox_ conf | fc7_mbox_ conf | conv6_2_mbox_ conf | conv7_2_mbox_ conf | conv8_2_mbox_ conf | conv9_2_mbox_ conf |
| ----- | ----------------------- | -------------- | ------------------ | ------------------ | ------------------ | ------------------ |
| size  | 84(类别*锚框数) 38 38   | 126 19 19      | 126 10 10          | 126 5 5            | 84 3 3             | 84 1 1             |

 

 最后经过 permute 层交换维度

| layer | conv4_3_norm_mbox_ conf_perm | fc7_mbox_ conf_perm | conv6_2_mbox_ conf_perm | conv7_2_mbox_ conf_perm | conv8_2_mbox_ conf_perm | conv9_2_mbox_ conf_perm |
| ----- | ---------------------------- | ------------------- | ----------------------- | ----------------------- | ----------------------- | ----------------------- |
| size  | 38 38 84                     | 19 19 126           | 10 10 126               | 5 5 126                 | 3 3 84                  | 1 1 84                  |

最后经过flatten 层整合

| layer | conv4_3_norm_mbox_ conf_flat | fc7_mbox_ conf_flat | conv6_2_mbox_ conf_flat | conv7_2_mbox_ conf_flat | conv8_2_mbox_ conf_flat | conv9_2_mbox_ conf_flat |
| ----- | ---------------------------- | ------------------- | ----------------------- | ----------------------- | ----------------------- | ----------------------- |
| size  | 121296                       | 45486               | 12600                   | 3150                    | 756                     | 84                      |

### 损失函数

**l:预测值 g:真实值 d:先验框的值**

认边界框$(d)$的中心$(cx, cy)$及其宽度$(w)$和高度$(h)$的偏移量
$$
L(x,c,l,g)=\frac{1}{N}(L_{conf}(x,c)+\alpha L_{loc}(x,l,g))
$$
定位损失：
$$
L_{loc}(x,l,g)=\sum_{i\in Pos}^{N}\sum_{m\in\{cx,cy,w,h\}}x_{ij}^{k}\mathrm{smooth}_{\mathrm{L}1}(l_{i}^{m}-\hat{g}_{j}^{m})\\
$$
拆分成x,y,w,h
$$
L_{loc}^{cx}(x,l,g) = \sum_{i \in Pos}^{N} x_{ij}^{k} \mathrm{smooth}{\mathrm{L}1}(l_{i}^{cx} - \hat{g}_{j}^{cx})\\
 L_{loc}^{cy}(x,l,g) = \sum_{i \in Pos}^{N} x_{ij}^{k} \mathrm{smooth}{\mathrm{L}1}(l_{i}^{cy} - \hat{g}_{j}^{cy})\\
 L_{loc}^{w}(x,l,g) = \sum_{i \in Pos}^{N} x_{ij}^{k} \mathrm{smooth}{\mathrm{L}1}(l_{i}^{w} - \hat{g}_{j}^{w}) \\
  L_{loc}^{h}(x,l,g) = \sum_{i \in Pos}^{N} x_{ij}^{k} \mathrm{smooth}{\mathrm{L}1}(l_{i}^{h} - \hat{g}_{j}^{h})
$$
分类损失：
$$
L_{conf}(x,c)=-\sum_{i\in Pos}^Nx_{ij}^plog(\hat{c}_i^p)-\sum_{i\in Neg}log(\hat{c}_i^0)\quad\mathrm{where}\quad\hat{c}_i^p=\frac{\exp(c_i^p)}{\sum_p\exp(c_i^p)}
$$


将真实框的坐标和尺寸转换为相对于默认框的偏移量和缩放比例
$$
\hat{g}_{j}^{cx}=(g_{j}^{cx}-d_{i}^{cx})/d_{i}^{w}\quad\hat{g}_{j}^{cy}=(g_{j}^{cy}-d_{i}^{cy})/d_{i}^{h}\\\hat{g}_{j}^{w}=\log\left(\frac{g_{j}^{w}}{d_{i}^{w}}\right)\quad\hat{g}_{j}^{h}=\log\left(\frac{g_{j}^{h}}{d_{i}^{h}}\right)
$$

#### smoothL1损失函数

$$
\mathrm{smooth}_{L_1}(x)=\begin{cases}0.5x^2&\mathrm{if} |x|<1\\|x|-0.5&\mathrm{otherwise}\end{cases}
$$

$$
MSE=\frac{\sum_{i=1}^n\left(f(x_i)-y_i\right)^2}n
$$

$$
MAE=\frac{\sum_{i=1}^n|f(x_i)-y_i|}n
$$

![comparison_plot](https://admin-hwj.oss-cn-beijing.aliyuncs.com/img/202411092014035.png)



### 正负样本

#### 匹配策略

​	将 prior box 和 grount truth box 按照IOU(>0.5)（本论文叫做JaccardOverlap）进行匹配，匹配成功则这个 prior box 就是 positive example（正样本），如果匹配不上，就是 negative example（负样本）

#### 难例挖掘

​	正负训练样本之间的显著不平衡，按**分类损失**从高到低排序，并选择最 高的示例,以便负例和正例之间的比例不超过3:1。

### 数据增广

为了使模型对各种输入目标大小和形状更鲁棒，每张训练图像都是通过以下选项之一进行随机采样的：

1. 直接使用整个**原始输入图像**。
2. **采样一个patch**（就是feature map 上裁下来一部分，使得与目标之间的最小Jaccard overlap重叠为0.1，0.3，0.5，0.7或0.9。（该策略生成的随机裁 剪可以被认为是一个**放大**操作）
3. **水平翻转**：以0.5的概率进行水平翻转

![image-20241104230812310](https://admin-hwj.oss-cn-beijing.aliyuncs.com/img/202411092014036.png)

4. 光度失真： Some improvements on deep convolutional neural network based image classification中提出的（考虑了可能存在的**测量误差或图像畸变**，并尝试应用类似的**技术来纠正**或减小这些误差。）



### 实验结果

表3 VOC2007评估结果

![image-20241105084428212](https://admin-hwj.oss-cn-beijing.aliyuncs.com/img/202411092014037.png)

表4 VOC2012评估结果

![image-20241105084623968](https://admin-hwj.oss-cn-beijing.aliyuncs.com/img/202411092014039.png)

表5 COCO评估结果

<img src="https://admin-hwj.oss-cn-beijing.aliyuncs.com/img/202411092014040.png" alt="image-20241105084638063" style="zoom: 67%;" />

分析：如上表所示，我们可以观察到在不同数据集上面（VOC2007、VOC2012、COCO），SSD512都获得了最佳的性能，在这里进行了加粗。可以看出，Faster-rcnn和SSD相比，在IOU上面最少相差3个点。



**SSD算法的优缺点**

**优点：**运行速度超过YOLO，精度超过Faster-rcnn（一定条件下，对于稀疏场景的大目标而言）。

**缺点：**网络中default box的基础大小和形状不能直接通过学习获得，而是需要手工设置。而网络中每一层feature使用的default box大小和形状恰好都不一样，导致调试过程非常依赖经验。

## 10/28-10/29 

**学习目标检测算法代码，开始实现SSD**

### 数据增强

#### 水平翻转

![98fc9c0d-a87b-400c-a7e7-4e4a28a3688d](https://admin-hwj.oss-cn-beijing.aliyuncs.com/img/202411092014041.png)

#### 垂直翻转

![96c0ef25-e8a9-4c0f-b340-874513d6b588](https://admin-hwj.oss-cn-beijing.aliyuncs.com/img/202411092014042.png)

#### 随即裁剪

![4cb7f5ef-1b23-4af6-83f2-90a2b5f5dc44](https://admin-hwj.oss-cn-beijing.aliyuncs.com/img/202411092014043.png)

#### 亮度调节

![74db3b5d-48f8-4f1c-9613-3d9f1ceead0d](https://admin-hwj.oss-cn-beijing.aliyuncs.com/img/202411092014044.png)

#### 颜色调节

![ec60f0cf-8e8d-4c42-829d-4af73f9b6ede](https://admin-hwj.oss-cn-beijing.aliyuncs.com/img/202411092014045.png)

#### SSD数据集预测香蕉数据集

![image-20241105055236965](https://admin-hwj.oss-cn-beijing.aliyuncs.com/img/202411092014046.png)



## 10/30-11/01 

**使用遗传算法求解多约束，多目标的仓库分配问题，边实现SSD**

![c4db41e9e5ee61bc1b7b85e5043e84e](https://admin-hwj.oss-cn-beijing.aliyuncs.com/img/202411092014047.png)

![b69f1235feb9389338af550c8e8f133](https://admin-hwj.oss-cn-beijing.aliyuncs.com/img/202411092014048.png)

## 11/02-11/03

 **学习注意力机制**

[8. 循环神经网络 — 动手学深度学习 2.0.0 documentation](https://zh-v2.d2l.ai/chapter_recurrent-neural-networks/index.html)

<img src="https://admin-hwj.oss-cn-beijing.aliyuncs.com/img/202411092014049.png" alt="image-20241105045829776" style="zoom: 33%;" />



[10. 注意力机制 — 动手学深度学习 2.0.0 documentation](https://zh-v2.d2l.ai/chapter_attention-mechanisms/index.html)

![../_images/qkv.svg](https://zh-v2.d2l.ai/_images/qkv.svg)

## 下周计划

1. 点云配准

- 了解一下三维点云配准的一个流程

- 调研一下有代码的方法，着手去改

2. slam

3. 水下拼接

## 思考





## 总结





ppt是思想的表达





